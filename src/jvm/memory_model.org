#+TITLE: 内存模型
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/main.css" />
#+HTML_LINK_UP: jvm_example.html   
#+HTML_LINK_HOME: jvm.html
#+OPTIONS: num:nil timestamp:nil ^:nil


*多任务处理* 在现代计算机操作系统中几乎已是一项必备的功能了。在许多情况下，让计算机同时去做几件事情，不仅是因为计算机的运算能力强大了，还有一个很重要的原因是 *计算机的 _运算_ 速度与它的 _存储_ 和 _通信_ 子系统速度的差距太大* ，大量的时间都花费在 _磁盘I/O_ 、 _网络通信_ 或者 _数据库_ 访问上。如果不希望处理器在大部分时间里都处于等待其他资源的状态，就必须使用一些手段去把处理器的运算能力“压榨”出来，否则就会造成很大的浪费，而让计算机同时处理几项任务则是最容易想到、也被证明是非常有效的“压榨”手段

除了充分利用计算机处理器的能力外， *一个服务端同时对多个客户端* 提供服务则是另一个更具体的并发应用场景。衡量一个服务性能的高低好坏， *每秒事务处理数* ( _TPS_ )是最重要的指标之一，它代表着 *一秒内服务端平均能响应的请求总数* ，而TPS值与程序的并发能力又有非常密切的关系。对于计算量相同的任务，程序线程并发协调得越有条不紊，效率自然就会越高；反之，线程之间 _频繁阻塞_ 甚至 _死锁_ ，将会 *大大降低程序的并发能力* 


服务端是Java语言最擅长的领域之一，这个领域的应用占了Java应用中最大的一块份额，不过如何写好并发应用程序却又是服务端程序开发的难点之一，处理好并发方面的问题通常需要更多的编码经验来支持。幸好Java语言和虚拟机提供了许多工具，把并发编程的门槛降低了不少。并且各种中间件服务器、各类框架都努力地替程序员处理尽可能多的线程并发细节，使得程序员在编码时能更关注业务逻辑，而不是花费大部分时间去关注此服务会同时被多少人调用、如何协调硬件资源

但是无论语言、中间件和框架如何先进，开发人员都不能期望它们能独立完成所有并发处理的事情，了解并发的内幕也是成为一个高级程序员不可缺少的课程

#+BEGIN_EXAMPLE
  Amdahl定律通过系统中并行化与串行化的比重来描述多处理器系统能获得的运算加速能力

  摩尔定律则用于描述处理器晶体管数量与运行效率之间的发展关系

  这两个定律的更替代表了近年来硬件发展从追求处理器频率到追求多核心并行处理的发展过程
#+END_EXAMPLE
* 硬件的效率与一致性
  先花费一点时间去了解一下物理计算机中的 *并发* 问题
  #+BEGIN_EXAMPLE
    物理机遇到的并发问题与虚拟机中的情况有不少相似之处

    物理机对并发的处理方案对于虚拟机的实现也有相当大的参考意义
  #+END_EXAMPLE

  _让计算机并发执行若干个运算任务_ 与 _更充分地利用计算机处理器的效能_ 之间的因果关系，看起来顺理成章，实际上它们之间的关系并没有想象中的那么简单，其中一个重要的复杂性来源是 *绝大多数的运算任务都不可能只靠处理器 _计算_ 就能完成* ，处理器至少要与 *内存交互* ，如 _读取运算数据_ 、 _存储运算结果_ 等，这个I/O操作是很难消除的（无法仅靠寄存器来完成所有运算任务）。由于计算机的存储设备与处理器的运算速度有几个数量级的差距，所以现代计算机系统都不得不加入一层 *读写速度尽可能接近处理器运算速度的高速缓存* 来作为内存与处理器之间的缓冲：
  + 将运算 *需要使用到的数据复制到缓存* 中，让运算能快速进行
  + 当运算结束后再从 *缓存同步计算结果回内存* 之中，这样处理器就无须等待缓慢的内存读写了 

  基于高速缓存的存储交互很好地解决了处理器与内存的速度矛盾，但是也为计算机系统带来更高的复杂度，因为它引入了一个新的问题： *缓存一致性* 。在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主内存（Main Memory），如下图所示：

  #+ATTR_HTML: image :width 50% 
  [[file:pic/cache_coherence.png]] 

  #+BEGIN_EXAMPLE
    当多个处理器的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致

    如果真的发生这种情况，那同步回到主内存时以谁的缓存数据为准呢？

    为了解决一致性的问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作

    这类协议有MSI、MESI、MOSI、Synapse、Firefly及Dragon Protocol等
  #+END_EXAMPLE
  以后将会多次提到的 _内存模型_ 一词，可以理解为 *在 _特定的操作协议_ 下，对 _特定的内存_ 或 _高速缓存_ 进行读写访问的过程抽象* 
  #+BEGIN_EXAMPLE
    不同架构的物理机器可以拥有不一样的内存模型，而Java虚拟机也有自己的内存模型

    这里介绍的内存访问操作与硬件的缓存访问操作具有很高的可比性
  #+END_EXAMPLE

  除了增加高速缓存之外，为了使得处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行 _乱序执行_ 优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其 *顺序性并不能靠代码的先后顺序来保证* 。与处理器的乱序执行优化类似，Java虚拟机的即时编译器中也有类似的 _指令重排序_ 优化
* JVM内存模型
  Java虚拟机规范中试图定义一种 _Java内存模型_ (JMM)来 *屏蔽掉各种硬件和操作系统的内存访问差异* ，以实现让Java程序在各种平台下都能达到一致的内存访问效果
  #+BEGIN_EXAMPLE
    在此之前，主流程序语言（如C/C++等）直接使用物理硬件和操作系统的内存模型

    由于不同平台上内存模型的差异，有可能导致程序在一套平台上并发完全正常，而在另外一套平台上并发访问却经常出错

    因此在某些场景就必须针对不同的平台来编写程序
  #+END_EXAMPLE

  定义Java内存模型并非一件容易的事情：
  + 这个模型必须定义得 *足够严谨* ，才能让Java的并发内存访问操作不会产生歧义
  + 也必须定义得 *足够宽松* ，使得虚拟机的实现有足够的自由空间去利用硬件的各种特性（寄存器、高速缓存和指令集中某些特有的指令）来获取更好的执行速度

  经过长时间的验证和修补，在 JDK 1.5（实现了 _JSR-133[2]_ ）发布后，Java内存模型已经成熟和完善起来了
** 主内存与工作内存 
   Java内存模型的主要目标是 *定义程序中各个变量的访问规则* ，即在虚拟机中将变量存储到内存和从内存中取出变量这样的底层细节。此处的 _变量_ 与 _Java编程中所说的变量_ 有所区别，它包括了 _实例字段_ 、 _静态字段_ 和 _构成数组对象的元素_ ，但不包括 *局部变量* 与 *方法参数* ，因为后者是 *线程私有的* ，不会被共享，自然就不会存在竞争问题
   #+BEGIN_EXAMPLE
     为了获得较好的执行效能

     Java内存模型并没有限制执行引擎使用处理器的特定寄存器或缓存来和主内存进行交互

     也没有限制即时编译器进行调整代码执行顺序这类优化措施
   #+END_EXAMPLE

   Java内存模型规定了 *所有的变量都存储在主内存* 中
   #+BEGIN_EXAMPLE
     此处的主内存与介绍物理硬件时的主内存名字一样，两者也可以互相类比，但此处仅是虚拟机内存的一部分
   #+END_EXAMPLE

   每条 *线程* 还有自己的 *工作内存* ：
   + 线程的工作内存中保存了被该线程使用到的 *变量的主内存副本拷贝*
   + 线程对变量的所有操作（ _读取_ 、 _赋值_ 等）都必须在 *工作内存* 中进行，而不能 *直接读写主内存中的变量*
   + *不同的线程* 之间也 *无法直接访问对方工作内存中的变量* ，线程间变量值的 *传递* 均需要通过 _主内存_ 来完成
   #+BEGIN_EXAMPLE
     可与前面讲的处理器高速缓存类比
   #+END_EXAMPLE

   线程、主内存、工作内存三者的交互关系如下图所示：
   #+ATTR_HTML: image :width 50% 
   [[file:pic/working_memory.png]] 


   注意：
   + 如果局部变量是一个 _reference_ 类型，它引用的对象在 *Java堆中可被各个线程共享* ，但是reference本身在 *Java栈的局部变量表* 中，它是 *线程私有的*
   + 拷贝副本，假设线程中访问一个10MB的对象，也会把这10MB的内存复制一份拷贝出来吗？ 事实上并不会如此， 这个 _对象的引用_ 、对象中 _某个在线程访问到的字段_ 是 *有可能存在拷贝* 的，但不会有虚拟机实现成把整个对象拷贝一次
   + *volatile* 变量依然有 *工作内存的拷贝* ，但是由于它 *特殊的操作顺序性* 规定，所以看起来如同直接在主内存中读写访问一般，因此这里的描述对于volatile也并不存在例外
   + 除了实例数据，Java堆还保存了对象的其他信息，对于HotSpot虚拟机来讲 
     + Mark Word
       + 存储对象哈希码
       + GC标志
       + GC年龄
       + 同步锁等信息
     + Klass Point : 指向存储类型元数据的指针
     + 字节对齐补白的填充数据 ： 如果实例数据刚好满足8字节对齐的话，则可以不存在补白
** 内存间交互操作
   关于主内存与工作内存之间具体的交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节，Java内存模型中定义了以下 *8种操作* 来完成，虚拟机实现时必须保证下面提及的 *每一种操作都是原子的、不可再分的* 
   #+BEGIN_EXAMPLE
     对于double和long类型的变量来说，load、store、read和write操作在某些平台上允许有例外
   #+END_EXAMPLE
   + *lock* （锁定）：作用于 _主内存_ 的变量，它把一个变量 *标识为一条线程独占* 的状态
   + *unlock* （解锁）：作用于 _主内存_ 的变量，它把一个处于 *锁定状态的变量释放* 出来，释放后的变量才可以被 _其他线程_ 锁定
   + *read* （读取）：作用于 _主内存_ 的变量，它把一个变量的值从 *主内存传输到线程的工作内存* 中，以便随后的 _load_ 动作使用
   + *load* （载入）：作用于 _工作内存_ 的变量，它把 _read_ 操作从主内存中得到的 *变量值放入工作内存的变量副本* 中
   +  *use* （使用）：作用于 _工作内存_ 的变量，它把工作内存中一个 *变量的值传递给执行引擎* ，每当虚拟机遇到一个 _需要使用到变量的值_ 的字节码指令时将会执行这个操作
   + *assign* （赋值）：作用于 _工作内存_ 的变量，它把一个 *从执行引擎接收到的值赋给工作内存的变量* ，每当虚拟机遇到一个给 _变量赋值_ 的字节码指令时执行这个操作
   + *store* （存储）：作用于 _工作内存_ 的变量，它把工作内存中一个 *变量的值传送到主内存* 中，以便随后的 _write_ 操作使用
   + *write* （写入）：作用于 _主内存_ 的变量，它把 _store_ 操作从 *工作内存中得到的变量的值放入主内存的变量* 中

*** 执行顺序
    + 如果要把一个变量从 *主内存复制到工作内存* ，那就要 *顺序地执行 _read_ 和 _load_ 操作*
    + 如果要把变量从 *工作内存同步回主内存* ，就要 *顺序地执行 _store_ 和 _write_ 操作* 

    #+BEGIN_EXAMPLE
      注意，Java内存模型只要求上述两个操作必须按顺序执行，而没有保证是连续执行

      也就是说，read与load之间、store与write之间是可插入其他指令的

      如对主内存中的变量a、b进行访问时，一种可能出现顺序是read a、read b、load b、load a
    #+END_EXAMPLE

    除此之外，Java内存模型还规定了在执行上述8种基本操作时必须满足如下规则：
    + 不允许 _read_ 和 _load_ 、 _store_ 和 _write_ 操作之一 *单独出现* ，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现
    + 不允许一个线程丢弃它的最近的assign操作，即变量在 *工作内存中改变了之后必须把该变化同步回主内存*
    + 不允许一个线程无原因地， *没有发生过任何 _assign_ 操作* ，把数据从线程的 *工作内存同步回主内存中*
    + 一个 *新的变量只能在主内存中诞生* ，不允许在工作内存中直接使用一个 *未被初始化* （ _load_ 或 _assign_ ）的变量，换句话说，就是 *对一个变量实施 _use_ 、 _store_ 操作之前，必须先执行过了 _assign_ 和 _load_ 操作*
    + 一个变量在 *同一个时刻只允许 _一条线程_ 对其进行 _lock_ 操作* 
      + 但 _lock_ 操作可以被 _同一条线程_  *重复执行多次* ，多次执行 lock 后，只有 *执行相同次数的 _unlock_ 操作* ，变量才会被解锁
      + 如果对一个变量执行 _lock_ 操作，那将会 *清空工作内存中此变量的值* ，在 _执行引擎_ 使用这个变量前，需要 *重新执行 _load_ 或 _assign_ 操作* 初始化变量的值
    + 如果一个变量 *事先没有被 _lock_ 操作锁定* ，那就 *不允许对它执行 _unlock_ 操作* ，也 *不允许去 unlock 一个 _被其他线程_ 锁定* 住的变量
      + 对一个变量执行 _unlock_ 操作之前，必须 *先把此变量同步回主内存中* ，也就是执行 _store_ 、 _write_ 操作

    #+BEGIN_EXAMPLE
       基于理解难度和严谨性考虑，最新的JSR-133文档中，已经放弃采用这8种操作去定义Java内存模型的访问协议了

      仅是描述方式改变了，Java内存模型并没有改变
    #+END_EXAMPLE

** volatile型变量的特殊规则
   关键字 *volatile* 可以说是Java虚拟机提供的 *最轻量级的同步机制* 

   #+BEGIN_EXAMPLE
     volatile 并不容易完全被正确、完整地理解，以至于许多程序员都习惯不去使用它，遇到需要处理多线程数据竞争问题的时候一律使用 synchronized 来进行同步

     了解volatile变量的语义对后面了解多线程操作的其他特性很有意义

     Java内存模型对volatile专门定义了一些特殊的访问规则，在介绍这些比较拗口的规则定义之前，先用不那么正式但通俗易懂的语言来介绍一下这个关键字的作用
   #+END_EXAMPLE

*** 可见性
    当一个变量定义为 *volatile* 之后，它将保证此变量对所有线程的 *可见性* ，这里的 _可见性_ 是指 *当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的* 。而普通变量不能做到这一点，普通变量的值在线程间传递均需要通过主内存来完成

    #+BEGIN_EXAMPLE
      例如，线程A修改一个普通变量的值，然后向主内存进行回写

      另外一条线程B在线程A回写完成了之后再从主内存进行读取操作，新变量值才会对线程B可见
    #+END_EXAMPLE

    关于volatile变量的可见性，经常会被开发人员误解，认为以下描述成立：“volatile变量对所有线程是立即可见的，对volatile变量所有的写操作都能立刻反应到其他线程之中，换句话说，volatile变量在各个线程中是一致的，所以基于volatile变量的运算在并发下是安全的”。这句话的论据部分并没有错，但是其论据并不能得出 *基于volatile变量的运算在并发下是安全的* 这个结论。volatile变量在 _各个线程的工作内存中不存在一致性问题_ （在各个线程的工作内存中，volatile变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题），但是Java里面的 *运算并非原子操作* ，导致 *volatile变量的运算在并发下一样是不安全的* ，可以通过一段简单的演示来说明原因，请看下面代码：

    #+BEGIN_SRC java
  class VolatileTest {

	  private static volatile int race = 0;

	  private static void increase() {
		  race++;
	  }

	  private static final int THREADS_COUNT = 20;

	  public static void main(String[] args) {
		  Thread[] threads = new Thread[THREADS_COUNT];
		  for (int i = 0; i < THREADS_COUNT; i++) {
			  threads[i] = new Thread(() -> {
					  for (int i1 = 0; i1 < 10000; i1++) {
						  increase();
					  }
			  });
			  threads[i].start();
		  }

		  // 等待所有累加线程都结束
		  while (Thread.activeCount() > 1)
			  Thread.yield();

		  System.out.println(race);
	  }
  }
    #+END_SRC

    #+BEGIN_EXAMPLE
      这段代码发起了20个线程，每个线程对race变量进行10000次自增操作

      如果这段代码能够正确并发的话，最后输出的结果应该是200000

      然而运行完这段代码之后，并不会获得期望的结果，而且会发现每次运行程序，输出的结果都不一样，都是一个小于200000的数字
    #+END_EXAMPLE

    问题就出现在自增运算 _race++_ 之中，用Javap反编译这段代码后会得到下面代码，发现只有一行代码的 _increase()_  方法在Class文件中是由 *4条字节码指令构成的* （return指令不是由race++产生的，这条指令可以不计算），从字节码层面上很容易就分析出并发失败的原因了：
    + 当 _getstatic_ 指令把 _race的值_ 取到 _操作栈顶_ 时， *volatile关键字保证了race的值在此时是正确的*
    + 但是在执行 _iconst_1_ 、 _iadd_ 这些指令的时候， *其他线程可能已经把race的值加大了* ，而 *在操作栈顶的值就变成了过期的数据* ，所以 _putstatic_ 指令执行后就可能 *把较小的race值同步回主内存* 之中

    #+BEGIN_SRC java
    public static void increase();
      descriptor: ()V
      flags: ACC_PUBLIC, ACC_STATIC
      Code:
	stack=2, locals=0, args_size=0
	   0: getstatic     #2                  // Field race:I
	   3: iconst_1
	   4: iadd
	   5: putstatic     #2                  // Field race:I
	   8: return
	LineNumberTable:
	  line 11: 0
	  line 12: 8
    #+END_SRC

    #+BEGIN_EXAMPLE
      客观地说，在此使用字节码来分析并发问题，仍然是不严谨的

      因为即使编译出来只有一条字节码指令，也并不意味执行这条指令就是一个原子操作

      一条字节码指令在解释执行时，解释器将要运行许多行代码才能实现它的语义

      如果是编译执行，一条字节码指令也可能转化成若干条本地机器码指令

      此处使用-XX：+PrintAssembly参数输出反汇编来分析会更加严谨一些，但考虑到阅读的方便，并且字节码已经能说明问题，所以此处使用字节码来分析
    #+END_EXAMPLE

    由于 _volatile_ 变量只能保证可见性，在不符合以下两条规则的运算场景中，仍然要通过 _加锁_ 来 *保证原子性* ：
    + 运算结果并 *不依赖变量的当前值* ，或者能够确保只有 *单一的线程* 修改变量的值
    + 变量 *不需要与其他的状态变量* 共同参与不变约束 

    如下的代码所示的这类场景就很适合使用 _volatile_ 变量来控制并发，当 _shutdown()_ 方法被调用时，能保证所有线程中执行的 _doWork()_ 方法都立即停下来：

    #+BEGIN_SRC java
  volatile boolean shutdownRequested；

  public void shutdown（）{
	  shutdownRequested=true；
		  }

  public void doWork（）{
	  while（！shutdownRequested）{
			  //do stuff
		  }
  }
    #+END_SRC


*** 指令重排
    使用volatile变量的第二个语义是 *禁止指令重排序优化* ，普通的变量仅仅会保证在 *该方法的执行过程中所有 _依赖赋值结果_ 的地方都能获取到正确的结果* ，而 *不能保证 _变量赋值操作_ 的顺序与 _程序代码中的执行顺序_ 一致* 。因为在一个线程的方法执行过程中无法感知到这点，这也就是Java内存模型中描述的所谓的 _线程内表现为串行的语义_ 

    继续通过一个例子来看看为何指令重排序会干扰程序的并发执行，演示程序如代码所示：
    #+BEGIN_SRC java
  Map configOptions；
  char[] configText；

  //此变量必须定义为volatile
  volatile boolean initialized=false；
  //假设以下代码在线程A中执行

  //模拟读取配置信息，当读取完成后将initialized设置为true以通知其他线程配置可用
	  configOptions = new HashMap()；
	  configText = readConfigFile(fileName)；
	  processConfigOptions(configText, configOptions)；
	  initialized = true；
 
 //假设以下代码在线程B中执行
  //等待initialized为true，代表线程A已经把配置信息初始化完成
	  while(！initialized){
		  sleep()；
	  }
  //使用线程A中初始化好的配置信息
	  doSomethingWithConfig()；
    #+END_SRC

    上面的程序是一段伪代码，其中描述的场景十分常见，只是在处理配置文件时一般不会出现并发而已。如果定义 initialized 变量时没有使用volatile修饰，就可能会由于 _指令重排序的优化_ ，导致 *位于线程A中最后一句的代码 _initialized=true_ 被提前执行* ，这样在线程B中使用配置信息的代码就可能出现错误，而volatile关键字则可以避免此类情况的发生

    #+BEGIN_EXAMPLE
      这里虽然使用Java作为伪代码，但所指的重排序优化是机器级的优化操作，提前执行是指这句话对应的汇编代码被提前执行
    #+END_EXAMPLE

    指令重排序是并发编程中最容易让开发人员产生疑惑的地方，除了上面伪代码的例子之外，再举一个可以实际操作运行的例子来分析volatile关键字是如何禁止指令重排序优化的。下面代码是一段标准的DCL单例代码，可以观察加入 volatile 和 未加入volatile关键字时所生成汇编代码的差别：

    #+BEGIN_SRC java
  public class Singleton {

	  private volatile static Singleton instance;

	  public static Singleton getInstance() {
		  if (instance == null) {
			  synchronized (Singleton.class) {
				  if (instance == null) {
					  instance = new Singleton();
				  }
			  }
		  }
		  return instance;
	  }

	  public static void main(String[] args) {
		  Singleton.getInstance();
	  }
  }
    #+END_SRC

    编译后，这段代码对instance变量赋值部分如下所示： 

    #+BEGIN_SRC sh
  0x01a3de0f：mov$0x3375cdb0，%esi         ；……beb0cd75 33
					  ；{oop（'Singleton'）}
  0x01a3de14：mov%eax，0x150（%esi）      ；……89865001 0000
  0x01a3de1a：shr$0x9，%esi                ；……c1ee09
  0x01a3de1d：movb$0x0，0x1104800（%esi）    ；……c6860048 100100
  0x01a3de24：lock addl$0x0，（%esp）        ；……f0830424 00
					  ；*putstatic instance
					  ；-
  Singleton：getInstance@24
    #+END_SRC


    通过对比就会发现，关键变化在于有volatile修饰的变量，赋值后（前面 _mov%eax，0x150(%esi)_ 这句便是赋值操作）多执行了一个 *lock addl ＄0x0，(%esp)* 操作，这个操作相当于一个 _内存屏障_ （指重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；但如果有两个或更多CPU访问同一块内存，且其中有一个在观测另一个，就需要内存屏障来保证一致性了。关键在于lock前缀，它的作用是使得 *本CPU的Cache写入了内存* ，该写入动作也会 *引起别的CPU或者别的内核无效化其Cache* ，这种操作相当于对Cache中的变量做了一次前面介绍Java内存模式中所说的 _store和write_ 操作。所以通过这样一个空操作，可让前面volatile变量的 *修改对其他CPU立即可见* 

    #+BEGIN_EXAMPLE
      lock 指令中的 addl ＄0x0，(%esp) （把ESP寄存器的值加0）显然是一个 空操作

      采用这个空操作而不是空操作指令nop是因为IA32手册规定 lock前缀不允许配合nop指令使用 
    #+END_EXAMPLE

    从硬件架构上讲，指令重排序是指 CPU采用了允许将 _多条指令不按程序规定的顺序分开发送给各相应电路单元处理_ 。但并不是说指令任意重排，CPU需要能 *正确处理指令依赖情况以保障程序能得出正确的执行结果* 
    #+BEGIN_EXAMPLE
      譬如 指令1 把地址 A 中的值加10，指令2把地址 A 中的值乘以2，指令3把地址 B 中的值减去3

      这时指令1和指令2是有依赖的，它们之间的顺序不能重排，因为 (A+10) * 2 与 A * 2 +10 显然不相等

      但指令3可以重排到指令1、2之前或者中间，只要保证CPU执行后面依赖到A、B值的操作时能获取到正确的A和B值即可

      所以在本内CPU中，重排序看起来依然是有序的
    #+END_EXAMPLE
    实际上， _lock addl＄0x0, (%esp)_ 指令把 _修改同步到内存_ 时，意味着 *所有之前的操作都已经执行完成* ，这样便形成了 _指令重排序无法越过内存屏障_ 的效果


*** 总结
    volatile 能让代码比使用其他的同步工具更快吗？在某些情况下，volatile的同步机制的性能确实要优于锁，但是由于虚拟机对锁实行的许多消除和优化，使得很难量化地认为volatile就会比synchronized快多少。如果让volatile自己与自己比较，那可以确定一个原则:  volatile变量 _读操作的性能消耗与普通变量几乎没有什么差别_ ，但是 _写操作则可能会慢一些_ ，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。不过即便如此，大多数场景下volatile的总开销仍然要比锁低，在volatile与锁之中选择的唯一依据仅仅是 *volatile的语义能否满足使用场景的需求* 

    最后，回头看一下Java内存模型中对volatile变量定义的特殊规则。假定 _T_ 表示一个 _线程_ ， _V_ 和 _W_ 分别表示两个 _volatile型变量_ ，那么在进行read、load、use、assign、store和write操作时需要满足如下规则：
    1. 只有当线程 T 对变量 V 执行的前一个动作是 _load_  的时候，线程 T 才能对变量 V 执行 _use_ 动作；并且，只有当线程 T 对变量 V 执行的后一个动作是 _use_ 的时候，线程 T 才能对变量 V 执行 _load_ 动作。线程T对变量V的use动作可以认为是和 线程 T 对变量 V 的 load、read动作相关联，必须连续一起出现。这条规则要求在 _工作内存_ 中， *每次使用 V 前都必须先从主内存刷新最新的值* ，用于保证能看见其他线程对变量 V 所做的修改后的值
    2. 只有当线程 T 对变量 V 执行的前一个动作是 _assign_ 的时候，线程 T 才能对变量 V 执行 _store_ 动作；并且，只有当线程 T 对变量 V 执行的后一个动作是 _store_ 的时候，线程 T 才能对变量 V 执行 _assign_ 动作。线程 T 对变量 V 的 assign动作可以认为是和线程T对变量V的 _store、write_ 动作相关联，必须连续一起出现。这条规则要求在工作内存中， *每次修改 V 后都必须立刻同步回主内存中* ，用于保证其他线程可以看到自己对变量V所做的修改

    #+BEGIN_EXAMPLE
      volatile屏蔽指令重排序的语义在JDK 1.5中才被完全修复

      此前的JDK中即使将变量声明为volatile也仍然不能完全避免重排序所导致的问题（主要是volatile变量前后的代码仍然存在重排序问题）

      这点也是在JDK 1.5之前的Java中无法安全地使用DCL（双锁检测）来实现单例模式的原因 
    #+END_EXAMPLE


*** 对于long和double型变量的特殊规则
    Java内存模型要求lock、unlock、read、load、assign、use、store、write这8个操作都具有原子性，但是对于64位的数据类型 ( _long_ 和 _double_ )，在模型中特别定义了一条相对宽松的规定： *允许虚拟机将没有被 _volatile_ 修饰的64位数据的读写操作划分为 _两次32位的操作_ 来进行* ，即允许虚拟机实现选择可以不保证64位数据类型的 _load_ 、_store_ 、 _read_ 和 _write_ 这4个操作的原子性，这点就是所谓的 _long和double的非原子性协定_ 

    如果有多个线程共享一个并未声明为volatile的long或double类型的变量，并且同时对它们进行读取和修改操作，那么某些线程可能会读取到一个既非原值，也不是其他线程修改值的代表了  _半个变量_ 的数值

    #+BEGIN_EXAMPLE
      不过这种读取到“半个变量”的情况非常罕见，在目前商用Java虚拟机中不会出现

      因为Java内存模型虽然允许虚拟机不把long和double变量的读写实现成原子操作

      但允许虚拟机选择把这些操作实现为具有原子性的操作，而且还“强烈建议”虚拟机这样实现
    #+END_EXAMPLE
    在实际开发中，目前各种平台下的商用虚拟机几乎都选择把64位数据的读写操作作为原子操作来对待，因此在编写代码时 *一般不需要把用到的long和double变量专门声明为volatile* 

** 原子性、可见性与有序性
   介绍完Java内存模型的相关操作和规则，再整体回顾一下这个模型的特征。Java内存模型是围绕着在并发过程中如何处理 *原子性* 、 *可见性* 和 *有序性* 这3个特征来建立的，逐个来看一下哪些操作实现了这3个特性

*** 原子性
    由Java内存模型来直接保证的 *原子性* 变量操作包括 _read_ 、 _load_ 、 _assign_ 、 _use_ 、 _store_ 和 _write_ 

    #+BEGIN_EXAMPLE
      大致可以认为基本数据类型的访问读写是具备原子性的，例外就是long和double的非原子性协定

      只要知道这件事情就可以了，无须太过在意这些几乎不会发生的例外情况
    #+END_EXAMPLE

    如果应用场景需要一个更大范围的原子性保证（经常会遇到），Java内存模型还提供了 *lock* 和 *unlock* 操作来满足这种需求，尽管虚拟机未把 _lock_ 和 _unlock_ 操作直接开放给用户使用，但是却提供了更高层次的字节码指令 *monitorenter* 和 *monitorexit* 来 _隐式_ 地使用这两个操作，这两个字节码指令反映到Java代码中就是 _同步块_ *synchronized* 关键字，因此在 _synchronized_ 块之间的操作也具备 _原子性_ 


*** 可见性
    可见性是指 *当一个线程修改了共享变量的值，其他线程能够立即得知这个修改* 。在讲解 _volatile_ 变量的时候已详细讨论过这一点。Java内存模型是通过 _在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值_ 这种 *依赖主内存作为传递媒介* 的方式来实现可见性的，无论是普通变量还是volatile变量都是如此。普通变量与 volatile 变量的区别是，volatile的 *特殊规则保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新* 。因此，可以说 _volatile_ 保证了多线程操作时 *变量的可见性* ，而普通变量则不能保证这一点

    除了 _volatile_ 之外，Java还有两个关键字能实现可见性，即 *synchronized* 和 *final* ：
    + synchronized：可见性是由 *对一个变量执行 _unlock_ 操作之前，必须先把此变量同步回主内存中（执行 _store_ 、 _write_ 操作）* 这条规则获得的
    + final: 可见性是由 *被final修饰的字段在构造器中一旦初始化完成，并且构造器没有把 _this 的引用传递_ 出去* ，那在其他线程中就能看见final字段的值。如下面代码所示，变量i与j都具备可见性，它们无须同步就能被其他线程正确访问：

    #+BEGIN_SRC java
  public static final int i；
  public final int j；

  static{
      i=0；
      //do something
  }

  {
      //也可以选择在构造函数中初始化
      j=0；
      //do something
  }
    #+END_SRC

    #+BEGIN_EXAMPLE
      this引用逃逸是一件很危险的事情，其他线程有可能通过这个引用访问到“初始化了一半”的对象
    #+END_EXAMPLE


*** 有序性
    Java内存模型的 *有序性* 在讲解volatile时也详细地讨论过了，Java程序中天然的有序性可以总结为：
    + 如果在 _本线程_ 内观察，所有的操作都是 *有序的* ：线程内表现为 _串行_ 的语义
    + 如果在 _一个线程中观察另一个线程_ ，所有的操作都是 *无序的* ：
      + _指令重排序_ 现象
      + _工作内存与主内存同步延迟_ 现象

    Java语言提供了 _volatile_ 和 _synchronized_ 两个关键字来保证线程之间操作的 *有序性* ：
    + volatile关键字本身就包含了 *禁止指令重排序* 的语义
    + synchronized则是由 _一个变量在同一个时刻只允许一条线程对其进行lock操作_ 这条规则获得的，这条规则决定了 *持有同一个锁的两个同步块只能 _串行地_ 进入* 

    #+BEGIN_EXAMPLE
      介绍完并发中3种重要的特性后，synchronized 关键字在需要这3种特性的时候都可以作为其中一种的解决方案

      因此大部分的并发控制操作都能使用 synchronized 来完成

      synchronized的“万能”也间接造就了它被程序员滥用的局面，越“万能”的并发控制，通常会伴随着越大的性能影响
    #+END_EXAMPLE
**** 先行发生原则
     如果Java内存模型中所有的有序性都仅仅靠 _volatile_ 和 _synchronized_ 来完成，那么有一些操作将会变得很烦琐，但是在编写Java并发代码的时候并没有感觉到这一点，这是因为Java语言中有一个 *先行发生* ( _happens-before_ )的原则。这个原则非常重要，它是 *判断数据是否存在竞争、线程是否安全* 的主要依据，依靠这个原则，可以通过几条规则一揽子地解决并发环境下两个操作之间是否可能存在冲突的所有问题

     先行发生是Java内存模型中定义的 *两项操作之间的偏序关系* ，如果说操作 A 先行发生于操作 B，其实就是说在发生操作 B 之前， *操作 A 产生的影响能被操作 B 观察到* ， *影响* 包括 _修改了内存中共享变量的值_ 、 _发送了消息_ 、 _调用了方法_ 等。可以举个例子来说明一下，如下面代码所示的这3句伪代码：
     #+BEGIN_SRC java
  //以下操作在线程A中执行
  i=1;

  //以下操作在线程B中执行
  j=i;

  //以下操作在线程C中执行
  i=2;
     #+END_SRC

     #+BEGIN_EXAMPLE
       假设线程 A 中的操作 i=1 先行发生于线程 B 的操作 j=i ，那么可以确定在线程 B 的操作执行后，变量 j 的值一定等于 1 ，得出这个结论的依据有两个：
       1. 根据先行发生原则， i=1 的结果可以被观察到
       2. 线程 C 还没登场，线程 A 操作结束之后 没有其他线程会修改变量 i 的值 

       现在再来考虑线程 C，依然保持线程 A 和线程 B 之间的先行发生关系，而线程 C 出现在线程 A 和线程 B 的操作之间，但是 线程 C 与 线程 B 没有先行发生关系 ，那 j 的值会是多少呢？

       答案是 不确定! ，1 和 2 都有可能

       因为线程 C 对变量 i 的影响可能会被线程B观察到，也可能不会，这时候线程 B 就存在 读取到过期数据的风险，不具备多线程安全性
     #+END_EXAMPLE

     下面是Java内存模型下一些“天然的”先行发生关系，这些先行发生关系 *无须任何同步器协助* 就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们 *随意地进行重排序* ：
     + 程序次序规则：在一个线程内，按照 _程序代码顺序_ ，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是 _控制流顺序_ 而不是程序代码顺序，因为要考虑分支、循环等结构
     + 管程锁定规则：一个 _unlock_ 操作 *先行发生* 于后面对 _同一个锁的lock_ 操作。这里必须强调的是 *同一个锁* ，而 _后面_ 是指 *时间上的先后顺序*
     + volatile变量规则：对一个 _volatile变量的写操作_ 先行发生于后面 _对这个变量的读操作_ ，这里的 _后面_ 同样是指 *时间上的先后顺序*
     + 线程启动规则： _Thread对象的start()_ 方法先行发生于 *此线程的每一个动作*
     + 线程终止规则：线程中的 _所有操作_ 都先行发生于对此线程的 _终止检测_
       + 通过 _Thread.join()_ 方法 *结束线程* 
       + _Thread.isAlive()_ 的返回值等手段 *检测到线程已经终止执行* 
     + 线程中断规则：对线程 _interrupt()方法的调用_ 先行发生于被 *中断线程的代码检测到中断事件的发生*
       + 通过 _Thread.interrupted()_ 方法 *检测到是否有中断发生* 
     + 对象终结规则：一个 _对象的初始化完成_ （构造函数执行结束）先行发生于它的 _finalize()_ 方法的开始
     + 传递性：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那就可以得出操作 A 先行发生于操作 C 的结论


     Java语言无须任何同步手段保障就能成立的先行发生规则就只有上面这些了， _使用这些规则去判定操作间是否具备顺序性_ ，对于 _读写共享变量_ 的操作来说，就是 *线程是否安全* ，可以从下面这个例子中感受一下 _时间上的先后顺序_ 与 *先行发生* 之间有什么不同。演示例子如下面所示：

     #+BEGIN_SRC java
  private int value=0;

  pubilc void setValue(int value){
	  this.value=value;                
  }

  public int getValue(){
	  return value;                
  }
     #+END_SRC

     这是是一组再普通不过的 getter/setter 方法，假设存在线程 A 和 B，线程A先（时间上的先后）调用了 _setValue(1)_ ，然后线程B调用了同一个对象的 _getValue()_ ，那么线程B 收到的返回值是什么？

     依次分析一下先行发生原则中的各项规则：
     + 由于两个方法分别由线程 A 和 线程 B 调用，不在一个线程中，所以 _程序次序_ 规则在这里不适用
     + 由于没有同步块，自然就不会发生lock和unlock操作，所以 _管程锁定_ 规则不适用
     + 由于value变量没有被volatile关键字修饰，所以 _volatile变量规则_ 不适用
     + 后面的 _线程启动_ 、 _终止_ 、 _中断_ 规则和 _对象终结_ 规则也和这里完全没有关系
     + 因为没有一个适用的先行发生规则，所以最后一条 _传递性_ 也无从谈起

     因此可以判定 _尽管线程 A 在操作时间上先于线程 B_ ，但是 *无法确定线程B中 _getValue()_ 方法的返回结果* ，换句话说，这里面的操作不是 *线程安全* 的

     #+BEGIN_EXAMPLE
       至少有两种比较简单的方案可以选择来修复这个问题：

       1. 把getter/setter方法都定义为 synchronized 方法，这样就可以套用管程锁定规则
       2. 把value定义为 volatile 变量，由于 setter 方法对 value 的修改不依赖 value 的原值，满足 volatile 关键字使用场景，这样就可以套用 volatile 变量规则来实现先行发生关系
     #+END_EXAMPLE 

     通过上面的例子，可以得出结论： *一个操作 _时间上_ 的先发生不代表这个操作会是 _先行_ 发生* ，那如果一个操作 _先行发生_ 是否就能推导出这个操作必定是 _时间上的先发生_ 呢？很遗憾，这个推论也是不成立的，一个典型的例子就是多次提到的 _指令重排序_ ，演示例子如下面所示：

     #+BEGIN_SRC java
  //以下操作在同一个线程中执行
  int i = 1;
  int j = 2;
     #+END_SRC

     这两条赋值语句在同一个线程之中，根据程序次序规则，_int i=1_ 的操作先行发生于 _int j=2_ ，但是 _int j=2_ 的代码完全可能先被处理器执行，这并不影响先行发生原则的正确性，因为 *在这条线程之中没有办法感知到这点* 

     *结论是：_时间先后顺序_ 与 _先行发生原则_ 之间基本没有太大的关系* ，所以衡量并发安全问题的时候不要受到时间顺序的干扰，一切必须以 *先行发生原则为准* 

* JVM线程实现
