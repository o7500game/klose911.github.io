#+TITLE: 运行期优化
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="css/main.css" />
#+HTML_LINK_UP: compilation_optimize.html   
#+HTML_LINK_HOME: jvm.html
#+OPTIONS: num:nil timestamp:nil ^:nil
在部分的商用虚拟机 (Sun HotSpot, IBM J9) 中，Java程序最初是通过 _解释器_ 进行解释执行的，当虚拟机发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为 *热点代码* 。为了提高热点代码的执行效率，在运行时， *虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化* ，完成这个任务的编译器称为 _即时编译器_ （Just In Time Compiler，下文中简称 _JIT编译器_ ）

#+BEGIN_EXAMPLE
    即时编译器并不是虚拟机必需的部分，Java虚拟机规范并没有规定Java虚拟机内必须要有即时编译器存在，更没有限定或指导即时编译器应该如何去实现

    但是，即时编译器编译性能的好坏、代码优化程度的高低却是衡量一款商用虚拟机优秀与否的最关键的指标之一，它也是虚拟机中最核心且最能体现虚拟机技术水平的部分

    由于Java虚拟机规范没有具体的约束规则去限制即时编译器应该如何实现，所以这部分功能完全是与虚拟机具体实现相关的内容

    如无特殊说明，下面提及的编译器、即时编译器都是指HotSpot虚拟机内的即时编译器，虚拟机也是特指HotSpot虚拟机
#+END_EXAMPLE
* HotSpot虚拟机内的即时编译器
  首先了解 HotSpot 虚拟机内的即时编译器的运作过程，同时，还要解决以下几个问题：
  + 为何 HotSpot 虚拟机要使用解释器与编译器并存的架构？
  + 为何 HotSpot 虚拟机要实现两个不同的即时编译器？
  + 程序何时使用解释器执行？何时使用编译器执行？
  + 哪些程序代码会被编译为本地代码？如何编译为本地代码？
  + 如何从外部观察即时编译器的编译过程和编译结果？

** 解释器 VS 编译器
   尽管并不是所有的 Java 虚拟机都采用解释器与编译器并存的架构，但许多主流的商用虚拟机，如 HotSpot、J9 等，都同时包含解释器与编译器。解释器与编译器两者各有优势：
   + 当程序需要 *迅速启动和执行* 的时候，解释器可以首先发挥作用，省去编译的时间，立即执行
   + 在程序运行后，随着时间的推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码之后，可以获取更高的 *执行效率* 
   + 当程序运行环境中内存资源限制较大（如部分嵌入式系统中），可以使用解释执行 *节约内存* ，反之可以使用编译执行来提升效率
   + 解释器还可以作为编译器激进优化时的一个 *逃生门* ，让编译器根据概率选择一些大多数时候都能提升运行速度的优化手段
     + 当激进优化的假设不成立，如加载了新类后类型继承结构出现变化、出现 _罕见陷阱_ 时可以通过 _逆优化_ 退回到解释状态继续执行

   #+BEGIN_EXAMPLE
     部分没有解释器的虚拟机中也会采用不进行激进优化的 C1 编译器担任 “逃生门” 的角色

     在虚拟机中习惯将 Client Compiler 称为 C1，将 Server Compiler 称为 C2 
   #+END_EXAMPLE

   在整个虚拟机执行架构中，解释器与编译器经常配合工作，如图所示：
   #+ATTR_HTML: image :width 70% 
   [[file:pic/jvm-interpreter-compiler.jpg]] 

   HotSpot虚拟机中内置了两个即时编译器，分别称为 _Client Compiler_ 和 _Server Compiler_ ，或者简称为 _C1编译器_ 和 _C2编译器_ （也叫Opto编译器）。目前主流的HotSpot虚拟机中，默认采用解释器与其中一个编译器直接配合的方式工作，程序使用哪个编译器，取决于 *虚拟机运行的模式* ，HotSpot虚拟机会根据自身版本与宿主机器的硬件性能自动选择运行模式，用户也可以使用 _-client_ 或 _-server_ 参数去强制指定虚拟机运行在Client模式或Server模式

   无论采用的编译器是Client Compiler还是Server Compiler，解释器与编译器搭配使用的方式在虚拟机中称为 _混合模式_  ：
   + 用户可以使用参数 _-Xint_ 强制虚拟机运行于 _解释模式_ ，这时编译器完全不介入工作， *全部代码都使用解释方式* 执行
   + 可以使用参数 _-Xcomp_ 强制虚拟机运行于 *编译模式* ，这时将 *优先采用编译方式* 执行程序，但是解释器仍然要在编译无法进行的情况下介入执行过程

   可以通过虚拟机的 _-version_ 命令的输出结果显示出这3种模式，如下面所示：
   #+BEGIN_SRC sh 
  C：\＞java -version
  java version"1.6.0_22"
  Java（TM）SE Runtime Environment（build 1.6.0_22-b04）
  Dynamic Code Evolution 64-Bit Server VM（build 0.2-b02-internal，19.0-b04-internal,mixed mode）

  C：\＞java -Xint-version
  java version"1.6.0_22"
  Java（TM）SE Runtime Environment（build 1.6.0_22-b04）
  Dynamic Code Evolution 64-Bit Server VM（build 0.2-b02-internal，19.0-b04-internal,interpreted mode）

  C：\＞java -Xcomp-version
  java version"1.6.0_22"
  Java（TM）SE Runtime Environment（build 1.6.0_22-b04）
  Dynamic Code Evolution 64-Bit Server VM（build 0.2-b02-internal，19.0-b04-internal,compiled mode）
   #+END_SRC
   由于即时编译器编译本地代码需要占用程序运行时间，要编译出优化程度更高的代码，所花费的时间可能更长；而且想要编译出优化程度更高的代码，解释器可能还要替编译器收集性能监控信息，这对解释执行的速度也有影响。为了在程序启动响应速度与运行效率之间达到最佳平衡，HotSpot虚拟机还会逐渐启用 *分层编译* 的策略

   分层编译根据编译器编译、优化的规模与耗时，划分出不同的编译层次，其中包括：
   + 第0层：程序解释执行，解释器 _不开启性能监控_ 功能 ，可触发第1层编译
   + 第1层，也称为C1编译，将 _字节码_ 编译为 _本地代码_ ，进行简单、可靠的优化，如有必要将加入性能监控的逻辑
   + 第2层（或2层以上），也称为C2编译，也是将字节码编译为本地代码，但是会 _启用一些编译耗时较长的优化_ ，甚至会根据性能监控信息进行一些 _不可靠的激进优化_ 

   #+BEGIN_EXAMPLE
     作为三大商用虚拟机之一的JRockit是个例外，它内部没有解释器，因此会存在“启动响应时间长”之类的缺点
     但它主要是面向服务端的应用，这类应用一般不会重点关注启动时间

     在虚拟机中习惯将Client Compiler称为C1，将Server Compiler称为C2。

     在最新的Sun HotSpot中，已经去掉了-Xcomp参数。

     Tiered Compilation在JDK 1.7之前需要使用-XX：+TieredCompilation参数来手动开启

     如果不开启分层编译策略，而虚拟机又运行在Server模式，Server Compiler需要性能监控信息提供编译依据
     则可以由解释器收集性能监控信息供Server Compiler使用
   #+END_EXAMPLE

   实施分层编译后，Client Compiler和Server Compiler将会同时工作，许多代码都可能会被多次编译：
   + 用Client Compiler获取更高的编译速度
   + 用Server Compiler来获取更好的编译质量
   + 在解释执行的时候也无须再承担收集性能监控信息的任务

** 编译对象与触发条件
   在运行过程中会被即时编译器编译的 _热点代码_ 有两类，即：
   + 被多次调用的方法
   + 被多次执行的循环体 

   #+BEGIN_EXAMPLE
     前者很好理解，一个方法被调用得多了，方法体内代码执行的次数自然就多，它成为 热点代码 是理所当然的

     而后者则为了解决一个方法只被调用过一次或少量的几次，但是方法体内部存在 循环次数较多的循环体 内部存在 循环次数较多的循环体 的问题
     这样循环次数较多的循环体的问题，这样循环体的代码也被重复执行多次，因此这些代码也应该认为是 “热点代码”
   #+END_EXAMPLE

   + 第一种情况，由于是由方法调用触发的编译，因此编译器理所当然地会以整个方法作为编译对象，这种编译也是虚拟机中标准的 JIT 编译方式
   + 第二种情况，尽管编译动作是由循环体所触发的，但编译器依然会以 *整个方法* （而不是单独的循环体）作为编译对象。这种编译方式因为编译发生在方法执行过程之中，因此形象地称之为 _栈上替换_ （简称为 OSR 编译，即方法栈帧还在栈上，方法就被替换了） 

   #+BEGIN_EXAMPLE
     在上面的文字描述中，无论是 “多次执行的方法”，还是 “多次执行的代码块”，所谓“多次”都不是一个具体、严谨的用语，那到底多少次才算“多次”呢？

     还有一个问题，就是虚拟机如何统计一个方法或一段代码被执行过多少次呢？

     解决了这两个问题，也就回答了即时编译被触发的条件
   #+END_EXAMPLE

   判断一段代码是不是热点代码，是不是需要触发即时编译，这样的行为称为 *热点探测* ，其实进行热点探测并不一定要知道方法具体被调用了多少次，目前主要的热点探测判定方式有两种，分别如下。
   + 基于 _采样_ 的热点探测：采用这种方法的虚拟机会 *周期性地检查各个线程的栈顶* ，如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是 *热点方法* 
     + 好处： *实现简单、高效* ，还可以 *很容易地获取方法调用* 关系（将调用堆栈展开即可）
     + 缺点： *很难精确* 地确认一个方法的热度，容易因为受到 _线程阻塞_ 或别的外界因素的影响而扰乱热点探测
   + 基于 _计数器_ 的热点探测：采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果执行次数超过一定的阈值就认为它是 “热点方法”
     + 实现起来 *麻烦* 一些，需要为每个方法建立并维护计数器，而且 *不能直接获取到方法的调用* 关系
     + 统计结果相对来说更加 *精确* 和严谨 

   #+BEGIN_EXAMPLE
     还有其他热点代码的探测方式，如基于“踪迹”（Trace）的热点探测再最近相当流行

     像 Firefox 中的 TraceMonkey 和 Dalvik 中新的 JIT 编译器都用了这种热点探测方式
   #+END_EXAMPLE

   在 HotSpot 虚拟机中使用的是第二种，基于计数器的热点探测方法，因此它为每个方法准备了两类计数器
   1. _方法调用_ 计数器
   2. _回边_ 计数器

   在确定虚拟机运行参数的前提下，这两个计数器都有一个确定的 _阈值_ ， *当计数器超过阈值溢出了，就会触发 JIT 编译* 

*** 方法调用计数器
    顾名思义，这个计数器就用于 *统计方法被调用的次数* ，它的默认阈值：
    + Client 模式下：1500 次
    + Server 模式下：10 000 次

    这个阈值可以通过虚拟机参数 _-XX:CompileThreshold_ 来人为设定

    当一个方法被调用时，首先检查该方法是否存在被 JIT 编译过的版本：
    + 如果存在，则优先使用编译后的本地代码来执行
    + 如果不存在已被编译过的版本：
      + 则将此方法的调用计数器值加 1
      + 判断 _方法调用计数器与回边计数器值之和_ 是否超过 _方法调用计数器的阈值_ ：
	+ 如果已超过阈值，那么将会 *向即时编译器提交一个该方法的代码编译请求* 
    + 如果不做任何设置，执行引擎 *并不会同步等待编译请求完成* ，而是 _继续进入解释器按照解释方式执行字节码_ ，直到提交的请求被编译器编译完成
    + 当编译工作完成之后，这个 *方法调用入口地址就会被系统自动改成新的* ，下一次调用该方法时就会使用已编译的版本

    整个 JIT 编译的交互过程如图所示：
    #+ATTR_HTML: image :width 70% 
    [[file:pic/invocation-counter-jit.jpg]] 

    如果不做任何设置，方法调用计数器统计的并不是 _方法被调用的绝对次数_ ，而是一个 *相对的执行频率* ，即 _一段时间之内方法被调用的次数_ 。当超过一定的时间限度，如果方法的调用次数仍然不足以让它提交给即时编译器编译，那这个方法的 _调用计数器就会被减少一半_ ，这个过程称为 _方法调用计数器热度的衰减_ ，而这段时间就称为此 _方法统计的半衰周期_ 。进行热度衰减的动作是在虚拟机 _进行垃圾收集时_ 顺便进行的：
    + 使用虚拟机参数 _-XX:-UseCounterDecay_ 来 *关闭热度衰减* ，让方法计数器统计方法调用的绝对次数，这样，只要系统运行时间足够长，绝大部分方法都会被编译成本地代码
    + 使用 _-XX:CounterHalfLifeTime_ 参数设置 *半衰周期的时间* ，单位是秒

*** 回边计数器
    回边计数器，它的作用是 *统计一个方法中循环体代码执行的次数* ，在 _字节码_ 中遇到 _控制流向后跳转的指令_ 称为 _回边_ 。显然，建立回边计数器统计的目的就是为了 *触发 OSR 编译* 

    关于回边计数器的阈值，虽然 HotSpot 虚拟机也提供了一个 -XX:BackEdgeThreashold 供用户设置，但是当前的虚拟机实际上并未使用此参数。因此需要设置另外一个参数 _-XX:OnStackReplacePercentage_ 来简介调整回边计数器的阈值，其计算公式如下：
    + 虚拟机运行在 Client 模式下，回边计数器阈值计算公式：
    #+BEGIN_EXAMPLE
      方法调用计数器阈值 * OSR 比率 / 100

      其中OSR比率的默认值为 140
    #+END_EXAMPLE 
    + 虚拟机运行在 Server 模式下，回边计数器阈值的计算公式为：
    #+BEGIN_EXAMPLE
      方法调用计数器阈值 * (OSR 比率 - 解释器监控比率)  / 100

      其中OSR比率的默认值为 140，解释器监控比率的默认值为 33，如果都取默认值，那 Server 模式虚拟机回边计数器的阈值为 10700
    #+END_EXAMPLE

    当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否有已经编译好的版本：
    + 如果有，它将会有限执行已编译的代码
    + 没有：回边计数器的值加 1
      + 判断方法调用 _计数器与回边计数器之和_ 是否超过 _回边计数器的阈值_ 
	+ 当超过阈值的时候，将会提交一个 OSR 编译请求，并且把 _回边计数器的值降低一些_ ，以便继续在解释器中执行循环，等待编译器输出编译结果

    整个执行过程如图所示：
    #+ATTR_HTML: image :width 70% 
    [[file:pic/backtrace-counter-jit.jpg]] 

    + 与方法计数器不同， 回边计数器 *没有计数热度衰减* 的过程，因此这个计数器统计的就是该方法循环执行的绝对次数
    + 当计数器溢出的时候，它还会把 *方法计数器的值也调整到溢出状态* ，这样下次再进入该方法的时候就会执行标准编译过程

    #+BEGIN_EXAMPLE
      最后需要提醒一点：上面的图示都仅仅描述了Client VM的即时编译方式，对于Server VM来说，执行情况会比上面的描述更复杂一些
    #+END_EXAMPLE

*** Java方法内存布局
    从理论上了解过编译对象和编译触发条件后，再从HotSpot虚拟机的源码中观察一下，在MethodOop.hpp（一个methodOop对象代表了一个Java方法）中，定义了 *Java方法在虚拟机中的内存布局* ，如下所示：

    #+BEGIN_SRC c
  // |------------------------------------------------------|
  // | header                                               |
  // | klass                                                |
  // |------------------------------------------------------|
  // | constMethodOop                 (oop)                 |
  // |------------------------------------------------------|
  // | methodData                     (oop)                 |
  // | interp_invocation_count                              |
  // |------------------------------------------------------|
  // | access_flags                                         |
  // | vtable_index                                         |
  // |------------------------------------------------------|
  // | result_index (C++ interpreter only)                  |
  // |------------------------------------------------------|
  // | method_size             | max_stack                  |
  // | max_locals              | size_of_parameters         |
  // |------------------------------------------------------|
  // |intrinsic_id|   flags    |  throwout_count            |
  // |------------------------------------------------------|
  // | num_breakpoints         |  (unused)                  |
  // |------------------------------------------------------|
  // | <strong>invocation_counter</strong>                                |
  // | <strong>backedge_counter</strong>                                  |
  // |------------------------------------------------------|
  // |           prev_time (tiered only, 64 bit wide)       |
  // |                                                      |
  // |------------------------------------------------------|
  // |                  rate (tiered)                       |
  // |------------------------------------------------------|
  // | code                           (pointer)             |
  // | i2i                            (pointer)             |
  // | adapter                        (pointer)             |
  // | <strong>from_compiled_entry</strong>         (pointer)             |
  // | <strong>from_interpreted_entry</strong>     (pointer)             |
  // |------------------------------------------------------|
  // | native_function       (present only if native)       |
  // | signature_handler     (present only if native)       |
  // |------------------------------------------------------|
    #+END_SRC

    在这个内存布局中，一行长度为 32 bit，从中可以清楚地看到：
    + _方法调用计数器_ (invocation_counter) 和 _回边计数器_ (backedge_counter) 所在的位置和长度
    + _from_compiled_entry_ 和 _from_interpreted_entry_ 这两个方法的入口

** 编译过程 
   在默认设置下，无论是 _方法调用_ 产生的 _即时编译_ 请求，还是 _OSR_ 编译请求，虚拟机在代码编译器还未完成之前，都仍然将按照 *解释方式* 继续执行，而编译动作则在 *后台的编译线程* 中进行。用户可以通过参数 _-XX:-BackgroundCompilation_ 来 *禁止后台编译* ，在禁止后台编译后，一旦达到JIT的编译条件， *执行线程向虚拟机提交编译请求后将会一直等待* ，直到编译过程完成后再开始执行编译器输出的本地代码

   那么在后台执行编译的过程中，编译器做了什么事情呢？Server Compiler和Client Compiler两个编译器的编译过程是不一样的

*** Client Compiler 
    对于Client Compiler来说，它是一个简单快速的 _三段式_ 编译器，主要的关注点在于 *局部性的优化* ，而放弃了许多耗时较长的全局优化手段
    1. *平台独立的前端* 将 _字节码_ 构造成一种 _高级中间代码_ 表示(HIR)：HIR使用 _静态单分配_ (SSA) 的形式来代表代码值，这可以使得一些在HIR的构造过程之中和之后进行的优化动作更容易实现。HIR之前编译器会在字节码上完成一部分 *基础优化* ：
       + 方法内联
       + 常量传播
       + ......
    2. *平台相关的后端* 从 _HIR_ 中产生 _低级中间代码_ (LIR)，而在此之前会在HIR上完成另外一些优化，以便让HIR达到更高效的代码表示形式：
       + 空值检查消除
       + 范围检查消除
       + ......
    3. *平台相关的后端* 使用 _线性扫描算法_ 在LIR上 *分配寄存器* ，并在LIR上做 _窥孔_ 优化，然后产生 _机器代码_ 

    Client Compiler的大致执行过程如图所示：
    #+ATTR_HTML: image :width 70% 
    [[file:pic/client-jit.jpg]] 


*** Server Compiler 
    Server Compiler则是专门面向服务端的典型应用并为服务端的性能配置特别调整过的编译器，也是一个充分优化过的高级编译器，几乎能达到GNU C++编译器使用-O2参数时的优化强度：
    + 执行所有 *经典的优化* 动作：
      + 无用代码消除
      + 循环展开
      + 循环表达式外提
      + 消除公共子表达式
      + 常量传播
      + 基本块重排序
      + ......
    + 实施一些与 *Java语言特性密切* 相关的优化技术：
      + 范围检查消除
      + 空值检查消除
    + 可能根据解释器或Client Compiler提供的 _性能监控_ 信息，进行一些 *不稳定的激进优化* ：
      + 守护内联
      + 分支频率预测
      + ......

    #+BEGIN_EXAMPLE
      这里涉及了许多编译原理和代码优化中的概念名词，没有这方面基础的读者，阅读起来会感觉到抽象和理论化

      有这种感觉并不奇怪，JIT编译过程本来就是一个虚拟机中最体现技术水平也是最复杂的部分，不可能以较短的篇幅就介绍得很详细，

      另外，这个过程对Java开发来说是透明的，程序员平时无法感知它的存在
    #+END_EXAMPLE

    Server Compiler的寄存器分配器是一个 _全局图着色分配器_ ，它可以充分利用某些处理器架构（如RISC）上的 _大寄存器集合_ 。以即时编译的标准来看，Server Compiler无疑是比较缓慢的，但它的编译速度依然远远超过传统的静态优化编译器，而且它相对于Client Compiler编译输出的代码质量有所提高，可以减少本地代码的执行时间，从而抵消了额外的编译时间开销，所以也有很多非服务端的应用选择使用Server模式的虚拟机运行

** 查看与分析即时编译结果 
   一般来说，虚拟机的即时编译过程对用户程序是完全透明的，虚拟机通过解释执行代码还是编译执行代码，对于用户来说并没有什么影响（执行结果没有影响，速度上会有很大差别），在大多数情况下用户也没有必要知道。但是虚拟机也提供了一些参数用来 *输出即时编译和某些优化手段* （如方法内联）的执行状况

   先看下测试代码：
   #+BEGIN_SRC java
  public static final int NUM = 15000;

  public static int doubleValue(int i) {
	  // 这个空循环用于后面演示JIT代码优化过程
	  for(int j=0; j<100000; j++);  
	  return i * 2;
  }

  public static long calcSum() {
	  long sum = 0;
	  for (int i = 1; i <= 100; i++) {
		  sum += doubleValue(i);
	  }
	  return sum;
  }

  public static void main(String[] args) {
	  for (int i = 0; i < NUM; i++) {
		  calcSum();
	  }
  }
   #+END_SRC

   运行这段代码，并且确认这段代码是否触发了即时编译，要知道某个方法是否被编译过，可以使用参数 _-XX:+PrintCompilation_ 要求虚拟机在即时编译时将 _被编译成本地代码的方法名称_ 打印出来，如下面所示：其中带有“%”的输出说明是由回边计数器触发的OSR编译

   #+BEGIN_EXAMPLE
     VM option'+PrintCompilation'
     310 1 java.lang.String：charAt（33 bytes）
     329 2 org.fenixsoft.jit.Test：calcSum（26 bytes）
     329 3 org.fenixsoft.jit.Test：doubleValue（4 bytes）
     332 1%org.fenixsoft.jit.Test：main@5（20 bytes）
   #+END_EXAMPLE

   从输出的确认信息中可以确认 _main()_ 、 _calcSum()_ 和 _doubleValue()_ 方法已经被编译，还可以加上参数 _-XX:+PrintInlining_ 要求虚拟机输出方法内联信息，如下面所示：

   #+BEGIN_EXAMPLE
     VM option'+PrintCompilation'
     VM option'+PrintInlining'
     273 1 java.lang.String：charAt（33 bytes）
     291 2 org.fenixsoft.jit.Test：calcSum（26 bytes）
     @9 org.fenixsoft.jit.Test：doubleValue inline（hot）
     294 3 org.fenixsoft.jit.Test：doubleValue（4 bytes）
     295 1%org.fenixsoft.jit.Test：main@5（20 bytes）
     @5 org.fenixsoft.jit.Test：calcSum inline（hot）
     @9 org.fenixsoft.jit.Test：doubleValue inline（hot）
   #+END_EXAMPLE

   输出中可以看到方法 _doubleValue()_ 被内联编译到 _calcSum()_ 中，而 _calcSum()_ 又被内联编译到方法 _main()_ 中，所以虚拟机再次执行 main() 方法的时候，calcSum() 和doubleValue() 方法都不会再被调用，它们的代码逻辑都被直接内联到main() 方法中了 （当然 main方法不会被再次调用，这里只是假设）

   除了查看哪些方法被编译之外，还可以进一步查看即时编译器生成的机器码内容，不过如果虚拟机输出一串0和1，对于阅读来说是没有意义的，机器码必须反汇编成基本的汇编语言才可能被阅读。虚拟机提供了一组通用的反汇编接口，可以接入各种平台下的反汇编适配器来使用，如使用32位80x86平台则选用hsdis-i386适配器，其余平台的适配器还有hsdis-amd64、hsdis-sparc和hsdis-sparcv9等，可以下载或自己编译出反汇编适配器，然后将其放置在JRE/bin/client或/server目录下，只要与jvm.dll的路径相同即可被虚拟机调用。在为虚拟机安装了反汇编适配器之后，就可以使用 _-XX:+PrintAssembly_ 参数要求虚拟机打印编译方法的汇编代码了

   如果没有HSDIS插件支持，也可以使用 _-XX:+PrintOptoAssembly_ （用于Server VM）或 _-XX:+PrintLIR_ （用于Client VM）来输出比较接近最终结果的中间代码表示，被编译后部分反汇编，使用 _-XX:+PrintOptoAssembly_ 的输出结果如下面所示：

   #+BEGIN_EXAMPLE
     ……
     000 B1：#N1＜-BLOCK HEAD IS JUNK Freq：1
     000 pushq rbp
     subq rsp，#16#Create frame
     nop#nop for patch_verified_entry
     006 movl RAX,RDX#spill
     008 sall RAX，#1
     00a addq rsp，16#Destroy frame
     popq rbp
     testl rax，[rip+#offset_to_poll_page]#Safepoint：poll for GC
     ……

     从阅读角度来说，使用 -XX:+PrintOptoAssembly 参数输出的伪汇编结果包含了更多的信息（主要是注释）
     利于阅读并理解虚拟机JIT编译器的优化结果

     使用-XX:+PrintAssembly参数输出反汇编信息需要Debug或者FastDebug版的虚拟机才能直接支持
     如果使用Product版的虚拟机，则需要加入参数-XX:+UnlockDiagnosticVMOptions打开虚拟机诊断模式后才能使用
   #+END_EXAMPLE

   如果除了本地代码的生成结果外，还想再进一步跟踪本地代码生成的具体过程，那还可以使用参数 _-XX:+PrintCFGToFile_ （使用Client Compiler）或 _-XX:PrintIdealGraphFile_ （使用Server Compiler）令虚拟机将编译过程中各个阶段的数据（例如，对C1编译器来说，包括 _字节码_ 、 _HIR生成_ 、 _LIR生成_ 、 _寄存器分配过程_ 、 _本地代码_ 生成等数据）输出到文件中。然后使用 _Java HotSpot Client Compiler Visualizer_ （用于分析Client Compiler）或 _Ideal Graph Visualizer_ （用于分析Server Compiler）打开这些数据文件进行分析

   Server Compiler的中间代码表示是一种名为 _Ideal_ 的 _SSA形式程序依赖图_ ，在运行Java程序的JVM参数中加入 _-XX:PrintIdealGraphLevel=2 -XX:PrintIdealGraphFile=ideal.xml_ ，编译后将产生一个名为 _ideal.xml_ 的文件，它包含了Server Compiler编译代码的过程信息，可以使用Ideal Graph Visualizer对这些信息进行分析

   Ideal Graph Visualizer加载ideal.xml文件后，在Outline面板上将显示程序运行过程中编译过的方法列表，如图所示。这里列出的方法是测试代码，其中 _doubleValue()_ 方法出现了两次，这是由于 *该方法的编译结果存在 _标准编译_ 和 _OSR编译_ 两个版本* 。在测试代码中特别为 _doubleValue()_ 方法增加了一个空循环，这个循环对方法的运算结果不会产生影响，但如果没有任何优化，执行空循环会占用CPU时间，到今天还有许多程序设计的入门教程把 *空循环当做程序延时* 的手段来介绍，在Java中这样的做法真的能起到延时的作用吗？ 

   #+ATTR_HTML: image :width 70% 
   [[file:pic/idea-graph-visualizer.jpg]] 

   展开方法根节点，可以看到下面罗列了方法优化过程的各个阶段的Ideal图，先打开 _After Parsing_ 这个阶段。JIT编译器在编译一个Java方法时，首先要把字节码解析成某种中间表示形式，然后才可以继续做分析和优化，最终生成代码。_After Parsing_ 就是Server Compiler刚完成解析，还没有做任何优化时的Ideal图表示。在打开这个图后，每一个方块就代表了一个程序的基本块，基本块的特点是只有 _唯一的一个入口_ 和 _唯一的一个出口_ ，只要基本块中 *第一条指令执行了，那么基本块内所有执行都会按照顺序仅执行一次* 

   doubleValue() 方法虽然只有简单的两行字，但是按基本块划分后，形成的图形结构要比想象中复杂得多，这一方面是要满足Java语言所定义的安全需要（如类型安全、空指针检查）和Java虚拟机的运作需要（如Safepoint轮询），另一方面是由于有些程序代码中一行语句就可能形成好几个基本块（例如循环）。例子中的doubleValue() 方法，如果忽略语言安全检查的基本块，可以简单理解为按顺序执行了以下几件事情：
   1. 程序入口，建立栈帧
   2. 设置j=0，进行Safepoint轮询，跳转到 4 的条件检查
   3. 执行j++
   4. 条件检查，如果j＜100000，跳转到 3
   5. 设置i=i*2，进行Safepoint轮询，函数返回

      #+ATTR_HTML: image :width 60% 
      [[file:pic/basic-block-1.jpg]] 

   以上几个步骤，反映到Ideal Graph Visualizer的图上，就是下图所示的内容。这样要看空循环是否优化，或者何时优化，只要观察代表循环的基本块是否消除，或者何时消除就可以了

   #+ATTR_HTML: image :width 40% 
   [[file:pic/basic-block-2.jpg]] 

   要观察到这一点，可以在Outline面板上右键点击 _Difference to current graph_ ，让软件自动分析指定阶段与当前打开的Ideal图之间的差异，如果基本块被消除了，将会以红色显示。对 _After Parsing_ 和 _PhaseIdealLoop 1_ 阶段的Ideal图进行差异分析，发现在 _PhaseIdealLoop 1_ 阶段循环操作被消除了，如下图所示：这也就说明 *空循环实际上是不会被执行的*  

   #+ATTR_HTML: image :width 40% 
   [[file:pic/basic-block-3.jpg]] 

   从 _After Parsing_ 阶段开始，一直到最后的 _Final Code_ 阶段，可以看到 doubleValue() 方法的Ideal图从繁到简的变迁过程，这也是Java虚拟机在尽力优化代码的过程。到了最后的 _Final Code_ 阶段，不仅 _空循环_ 的开销消除了，许多 _语言安全_ 和 _Safepoint轮询_ 的操作也一起消除了，因为编译器判断 *即使不做这些安全保障，虚拟机也不会受到威胁* 

* 编译优化技术 
  #+BEGIN_EXAMPLE
    Java 程序员有一个共识，以编译方式执行本地代码比解释方式更快，之所以有这样的共识，除去虚拟机解释执行字节码时额外消耗时间的原因外

    还有一个很重要的原因就是虚拟机设计团队几乎把对代码的所有优化措施都集中在了即时编译器之中

    在 JDK 1.3 之后，javac 就去除了 -O 选项，不会生成任何字节码级别的优化代码了

    因此一般来说，即时编译器产生的本地代码会比 javac 产生的字节码更加优秀
  #+END_EXAMPLE

  下面将介绍一些 HotSpot 虚拟机的即时编译器在生成代码时采用的代码优化技术
** 优化技术概览  
   在 Sun 官方的 Wiki 上，HotSpot 虚拟机设计团队列出了一个相对比较全面的、在即时编译器中采用的优化技术列表，见表 11-1），其中有不少经典编译器的优化手段，也有许多针对 Java 语言（准确地说是针对运行在 Java 虚拟机上的所有语言）本身进行的优化技术：

   #+CAPTION: 即时编译技术优化一览
   #+ATTR_HTML: :border 1 :rules all :frame boader
   | 类型                   | 优化策略                     |
   | 编译器策略             | 延迟编译                     |
   |                        | 分层编译                     |
   |                        | 栈上替换                     |
   |                        | 延迟优化                     |
   |                        | 程序依赖图表示               |
   | 基于性能监控的优化技术 | 乐观空值断言                 |
   |                        | 乐观类型断言                 |
   |                        | 乐观类型增强                 |
   |                        | 乐观数组长度增强             |
   |                        | 裁剪未被选择的分支           |
   |                        | 乐观的多态内联               |
   |                        | 分支频率预测                 |
   |                        | 调用频率预测                 |
   | 基于证据的优化技术     | 精确类型推断                 |
   |                        | 内存值推断                   |
   |                        | 内存值跟踪                   |
   |                        | 常量拆叠                     |
   |                        | 重组                         |
   |                        | 操作符退化                   |
   |                        | 空值检查消除                 |
   |                        | 类型检测退化                 |
   |                        | 类型检测消除                 |
   |                        | 代数化简                     |
   |                        | 公共子表达式消除             |
   | 数据流敏感重写         | 条件常量传播                 |
   |                        | 基于流承载的类型缩减转换     |
   |                        | 无用代码清除                 |
   | 语言相关的优化技术     | 类型继承关系分析             |
   |                        | 去虚拟机化                   |
   |                        | 符号常量传播                 |
   |                        | 自动装箱传播                 |
   |                        | 逃逸分析                     |
   |                        | 锁清除                       |
   |                        | 锁膨胀                       |
   |                        | 清除反射                     |
   | 内存及代码位置变换     | 表达式提升                   |
   |                        | 表达式下沉                   |
   |                        | 冗余存储消除                 |
   |                        | 相邻存储合并                 |
   |                        | 交汇点分离                   |
   | 循环变换               | 循环展开                     |
   |                        | 循环剥离                     |
   |                        | 安全点消除                   |
   |                        | 迭代范围分离                 |
   |                        | 范围检查消除                 |
   |                        | 循环向量化                   |
   | 全局代码调整           | 内联                         |
   |                        | 全局代码外提                 |
   |                        | 基于热度的代码布局           |
   |                        | Switch调整                   |
   | 控制流图变换           | 本地代码编排                 |
   |                        | 本地代码封包                 |
   |                        | 延迟槽填充                   |
   |                        | 着色图寄存器分配             |
   |                        | 线性扫描寄存器分配           |
   |                        | 复写聚合                     |
   |                        | 常量分裂                     |
   |                        | 复写移除                     |
   |                        | 地址模式匹配                 |
   |                        | 指令窥孔优化                 |
   |                        | 基于确定有限状态机的代码生成 |

为了消除对这些优化技术的陌生感，先举一个简单的例子，即通过大家熟悉的Java代码变化来展示其中几种优化技术是如何发挥作用的（仅使用Java代码来表示而已）。首先从原始代码开始，如下所示：

   #+BEGIN_SRC java
  static class B{
	  int value;
	  final int get() {
		  return value;
	  }
  }
  public void foo() {
	  y = b.get();
	  // ...do stuff...
	  z = b.get();
	  sum = y + z;
  }
   #+END_SRC

   #+BEGIN_EXAMPLE
     这些代码优化变换是建立在代码的某种中间表示或机器码之上的，绝不是建立在Java 源码之上的

     为了展示方便，使用了 Java 语言的语法来表示这些优化技术所发挥的作用
   #+END_EXAMPLE

   上面代码已经非常简单了，但是仍然有许多优化的余地：
   + _方法内联_ ，方法内联的重要性要高于其他优化措施，它的主要目的有两个：
     + *去除方法调用的成本* ：如建立栈帧等
     + *其他优化建立良好的基础* 

   方法内联膨胀之后可以便于在更大范围上采取后续的优化手段，从而获取更好的优化效果。因此，各种编译器一般都会把内联优化放在优化序列的最靠前位置。内联后的代码如下所示：

   #+BEGIN_SRC java
  public void foo() {
	  y = b.value;
	  // ...do stuff...
	  z = b.value;
	  sum = y + z;
  }
   #+END_SRC

   + _冗余访问消除_ ，假设代码中间注释掉的 “do stuff...” 所代表的操作不会改变 b.value 的值，那就可以把 _z = b.value_ 替换为 _z = y_ ，因为上一句 _y = b.value_ 已经保证了变量 _y_ 与 _b.value_ 是一致的，这样就可以 *不再去访问对象 b 的局部变量* 了。如果把 b.value 看做是一个表达式，那也可以把这项优化看成是 _公共子表达式消除_ ，优化后的代码如下所示

   #+BEGIN_SRC java
  public void foo() {
	  y = b.value;
	  // ...do stuff...
	  z = y;
	  sum = y + z;
  }
   #+END_SRC

   + _复写传播_ ，因为在这段程序的逻辑中并没有必要使用一个额外的变量 _z_ ，它与变量 _y_ 是完全相等的，因此可以使用  _y_ 来代替 _z_ 。复写传播之后程序如下所示：

   #+BEGIN_SRC java
  public void foo() {
	  y = b.value;
	  // ...do stuff...
	  y = y;
	  sum = y + y;
  }
   #+END_SRC 

   + _无用代码消除_ 。无用代码可能是永远不会被执行的代码，也可能是完全没有意义的代码，因此，它又形象地称为 “Dead Code”，在上面代码 _y = y_ 是没有意义的，把它消除后的程序如代码如下所示：

   #+BEGIN_SRC java
  public void foo() {
	  y = b.value;
	  // ...do stuff...
	  sum = y + y;
  }
   #+END_SRC

   #+BEGIN_EXAMPLE
     经过四次优化之后，最后的代码与最初的代码所达到的效果是一致的

     但是前者比后者省略了许多语句（体现在字节码和机器码指令上的差距会更大），执行效率也会更高

     编译器的这些优化技术实现起来也许比较复杂，但是要理解它们的行为对于一个普通的程序员来说是没有困难的
   #+END_EXAMPLE

   接下来，将继续查看如下的几项最有代表性的优化技术是如何运作的，它们分别是：
   + 语言无关的经典优化技术之一： _公共子表达式消除_ 
   + 语言相关的经典优化技术之一： _数组范围检查消除_ 
   + 最重要的优化技术之一： _方法内联_
   + 最前沿的优化技术之一： _逃逸分析_ 
** 公共子表达式消除 

** 数组边界检查消除 

** 方法内联 

** 逃逸分析 

   [[file:compilation_optimize.org][Previous：编译器优化]]

   [[file:jvm.org][Home：目录]]
